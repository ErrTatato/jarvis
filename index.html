<!DOCTYPE html>
<html lang="it">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>J.A.R.V.I.S.</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body {
            background: #000;
            overflow: hidden;
            font-family: 'Courier New', monospace;
            color: #00d4ff;
            -webkit-user-select: none;
            user-select: none;
        }
        
        /* CANVAS PARTICLES */
        canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }
        
        /* ORB CONTAINER */
        .orb-container {
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 300px;
            height: 300px;
            cursor: pointer;
        }
        
        /* ORB */
        .orb {
            position: absolute;
            top: 50%;
            left: 50%;
            width: 200px;
            height: 200px;
            margin: -100px 0 0 -100px;
            border-radius: 50%;
            background: radial-gradient(circle at 30% 30%, #4da6ff, #0066cc, #003366);
            box-shadow: 
                0 0 60px rgba(0, 150, 255, 0.8),
                0 0 120px rgba(0, 150, 255, 0.5),
                inset 0 0 60px rgba(0, 150, 255, 0.3);
            animation: idle-pulse 3s ease-in-out infinite;
            transition: all 0.3s ease;
        }
        
        .orb:active {
            transform: scale(0.95);
        }
        
        /* ANIMATIONS */
        @keyframes idle-pulse {
            0%, 100% { 
                transform: scale(1); 
                box-shadow: 0 0 60px rgba(0, 150, 255, 0.8), 0 0 120px rgba(0, 150, 255, 0.5); 
            }
            50% { 
                transform: scale(1.05); 
                box-shadow: 0 0 80px rgba(0, 150, 255, 1), 0 0 160px rgba(0, 150, 255, 0.7); 
            }
        }
        
        @keyframes listening-pulse {
            0%, 100% { 
                transform: scale(1.1); 
                box-shadow: 0 0 100px rgba(255, 200, 0, 1), 0 0 200px rgba(255, 200, 0, 0.8); 
            }
            50% { 
                transform: scale(1.2); 
                box-shadow: 0 0 120px rgba(255, 200, 0, 1), 0 0 240px rgba(255, 200, 0, 0.9); 
            }
        }
        
        @keyframes speaking-pulse {
            0%, 100% { 
                transform: scale(1.15); 
                box-shadow: 0 0 120px rgba(0, 255, 150, 1), 0 0 240px rgba(0, 255, 150, 0.8); 
            }
            50% { 
                transform: scale(1.25); 
                box-shadow: 0 0 150px rgba(0, 255, 150, 1), 0 0 300px rgba(0, 255, 150, 0.9); 
            }
        }
        
        .orb.listening {
            background: radial-gradient(circle at 30% 30%, #ffeb3b, #ffc107, #ff9800);
            animation: listening-pulse 1s ease-in-out infinite;
        }
        
        .orb.speaking {
            background: radial-gradient(circle at 30% 30%, #00ff88, #00cc66, #009944);
            animation: speaking-pulse 0.8s ease-in-out infinite;
        }
        
        .orb.offline {
            background: radial-gradient(circle at 30% 30%, #666, #444, #222);
            box-shadow: 0 0 30px rgba(100, 100, 100, 0.5);
            animation: none;
        }
        
        /* STATUS TEXT */
        .status-text {
            position: fixed;
            bottom: 80px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 13px;
            opacity: 0.8;
            text-align: center;
            text-transform: uppercase;
            letter-spacing: 3px;
            text-shadow: 0 0 10px rgba(0, 212, 255, 0.8);
        }
        
        /* MODE TOGGLE */
        .mode-toggle {
            position: fixed;
            bottom: 30px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 15px;
            background: rgba(0, 30, 60, 0.8);
            padding: 12px 20px;
            border-radius: 25px;
            border: 1px solid rgba(0, 212, 255, 0.3);
            backdrop-filter: blur(10px);
        }
        
        .mode-btn {
            background: rgba(0, 100, 200, 0.3);
            border: 1px solid rgba(0, 212, 255, 0.5);
            color: #00d4ff;
            padding: 8px 16px;
            border-radius: 15px;
            cursor: pointer;
            font-size: 11px;
            text-transform: uppercase;
            letter-spacing: 1px;
            transition: all 0.3s;
            font-family: 'Courier New', monospace;
        }
        
        .mode-btn.active {
            background: rgba(0, 212, 255, 0.8);
            color: #000;
            box-shadow: 0 0 20px rgba(0, 212, 255, 0.8);
        }
        
        .mode-btn:active {
            transform: scale(0.95);
        }
        
        /* HINT TEXT */
        .hint {
            position: fixed;
            top: 30px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 11px;
            opacity: 0.5;
            text-align: center;
            letter-spacing: 2px;
        }
    </style>
</head>
<body>
    <canvas id="particles"></canvas>
    
    <div class="hint" id="hint">HOLD ORB TO SPEAK</div>
    
    <div class="orb-container" id="orbContainer">
        <div class="orb offline" id="orb"></div>
    </div>
    
    <div class="status-text" id="status">OFFLINE</div>
    
    <div class="mode-toggle">
        <button class="mode-btn active" id="btnHold">üé§ HOLD</button>
        <button class="mode-btn" id="btnVoice">üéôÔ∏è VOICE</button>
    </div>

    <script>
        // ========================================================================
        // JARVIS - UNIFIED INTERFACE
        // ========================================================================
        
        const canvas = document.getElementById('particles');
        const ctx = canvas.getContext('2d');
        const orb = document.getElementById('orb');
        const orbContainer = document.getElementById('orbContainer');
        const statusText = document.getElementById('status');
        const hint = document.getElementById('hint');
        const btnHold = document.getElementById('btnHold');
        const btnVoice = document.getElementById('btnVoice');
        
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;
        
        // STATE
        let currentMode = 'hold'; // 'hold' o 'voice'
        let peerConnection = null;
        let dataChannel = null;
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let recognition = null;
        let audioQueue = [];
        let isPlayingAudio = false;
        
        // PARTICLES
        const particles = [];
        const particleCount = 80;
        
        class Particle {
            constructor() {
                this.reset();
            }
            reset() {
                this.x = canvas.width / 2;
                this.y = canvas.height / 2;
                const angle = Math.random() * Math.PI * 2;
                const speed = Math.random() * 1.5 + 0.3;
                this.vx = Math.cos(angle) * speed;
                this.vy = Math.sin(angle) * speed;
                this.life = 1;
                this.decay = Math.random() * 0.008 + 0.003;
                this.size = Math.random() * 2 + 0.5;
            }
            update() {
                this.x += this.vx;
                this.y += this.vy;
                this.life -= this.decay;
                if (this.life <= 0) this.reset();
            }
            draw() {
                ctx.save();
                ctx.globalAlpha = this.life * 0.6;
                ctx.fillStyle = '#00d4ff';
                ctx.beginPath();
                ctx.arc(this.x, this.y, this.size, 0, Math.PI * 2);
                ctx.fill();
                ctx.restore();
            }
        }
        
        for (let i = 0; i < particleCount; i++) {
            particles.push(new Particle());
        }
        
        function animateParticles() {
            ctx.fillStyle = 'rgba(0, 0, 0, 0.08)';
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            particles.forEach(p => { p.update(); p.draw(); });
            requestAnimationFrame(animateParticles);
        }
        animateParticles();
        
        // STATUS FUNCTIONS
        function setStatus(text, state) {
            statusText.textContent = text;
            orb.className = `orb ${state}`;
        }
        
        function log(msg) {
            console.log(`[JARVIS] ${msg}`);
        }
        
        // MODE SWITCHING
        btnHold.addEventListener('click', () => {
            if (currentMode === 'hold') return;
            currentMode = 'hold';
            btnHold.classList.add('active');
            btnVoice.classList.remove('active');
            hint.textContent = 'HOLD ORB TO SPEAK';
            if (recognition) {
                recognition.stop();
                recognition = null;
            }
            if (dataChannel && dataChannel.readyState === 'open') {
                setStatus('ONLINE - HOLD MODE', '');
            }
            log('Mode: HOLD');
        });
        
        btnVoice.addEventListener('click', () => {
            if (currentMode === 'voice') return;
            currentMode = 'voice';
            btnVoice.classList.add('active');
            btnHold.classList.remove('active');
            hint.textContent = 'VOICE ACTIVATED';
            if (dataChannel && dataChannel.readyState === 'open') {
                initVoiceRecognition();
            }
            log('Mode: VOICE');
        });
        
        // WEBRTC INIT
        async function initWebRTC() {
            try {
                setStatus('CONNECTING...', '');
                peerConnection = new RTCPeerConnection({
                    iceServers: [{ urls: 'stun:stun.l.google.com:19302' }]
                });

                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true } 
                });
                
                stream.getTracks().forEach(track => peerConnection.addTrack(track, stream));
                dataChannel = peerConnection.createDataChannel('jarvis');
                
                dataChannel.onopen = () => {
                    log('ONLINE');
                    setStatus('ONLINE - HOLD MODE', '');
                    dataChannel.send(JSON.stringify({type: 'client_ready'}));
                };

                dataChannel.onmessage = (event) => {
                    try {
                        const msg = JSON.parse(event.data);
                        handleServerMessage(msg);
                    } catch (e) {}
                };

                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);

                const response = await fetch('/offer', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ sdp: offer.sdp, type: offer.type })
                });

                const answer = await response.json();
                await peerConnection.setRemoteDescription(answer);
            } catch (error) {
                log(`Error: ${error.message}`);
                setStatus('CONNECTION FAILED', 'offline');
                alert(`Errore connessione:\n${error.message}\n\nPermetti accesso al microfono!`);
            }
        }
        
        // VOICE RECOGNITION (modalit√† Voice)
        function initVoiceRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                alert('Speech recognition non supportato');
                return;
            }
            
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = false;
            recognition.lang = 'it-IT';
            
            recognition.onstart = () => {
                log('Voice recognition started');
                setStatus('LISTENING...', 'listening');
            };
            
            recognition.onresult = (event) => {
                const last = event.results.length - 1;
                const text = event.results[last][0].transcript.trim();
                log(`Voice: "${text}"`);
                setStatus('PROCESSING...', '');
                if (dataChannel && dataChannel.readyState === 'open') {
                    dataChannel.send(JSON.stringify({ type: 'user_question', text: text }));
                }
            };
            
            recognition.onerror = (event) => {
                if (event.error !== 'no-speech') {
                    log(`Voice error: ${event.error}`);
                }
            };
            
            recognition.onend = () => {
                if (currentMode === 'voice' && dataChannel && dataChannel.readyState === 'open') {
                    setTimeout(() => recognition.start(), 100);
                }
            };
            
            recognition.start();
        }
        
        // HOLD TO TALK (modalit√† Hold)
        async function startRecording() {
            if (currentMode !== 'hold') return;
            
            try {
                audioChunks = [];
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true, sampleRate: 16000 } 
                });
                
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });
                mediaRecorder.ondataavailable = (event) => { if (event.data.size > 0) audioChunks.push(event.data); };
                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm;codecs=opus' });
                    await sendAudioToWhisper(audioBlob);
                    stream.getTracks().forEach(track => track.stop());
                };
                
                mediaRecorder.start();
                isRecording = true;
                setStatus('RECORDING...', 'listening');
                log('Recording started');
            } catch (error) {
                log(`Recording error: ${error}`);
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                setStatus('PROCESSING...', '');
                log('Recording stopped');
            }
        }
        
        async function sendAudioToWhisper(audioBlob) {
            try {
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.webm');
                
                const response = await fetch('/transcribe', { method: 'POST', body: formData });
                const result = await response.json();
                
                if (result.error) throw new Error(result.error);
                
                const transcription = result.text || '';
                log(`Whisper: "${transcription}"`);
                
                if (transcription.trim() && dataChannel && dataChannel.readyState === 'open') {
                    dataChannel.send(JSON.stringify({ type: 'user_question', text: transcription }));
                } else {
                    setStatus('NOT UNDERSTOOD', '');
                    setTimeout(() => setStatus('ONLINE - HOLD MODE', ''), 2000);
                }
            } catch (error) {
                log(`Whisper error: ${error}`);
                setStatus('ERROR', 'offline');
                setTimeout(() => setStatus('ONLINE - HOLD MODE', ''), 2000);
            }
        }
        
        // MESSAGE HANDLER
        function handleServerMessage(msg) {
            switch (msg.type) {
                case 'audio_chunk':
                    log('Audio chunk received');
                    setStatus('SPEAKING...', 'speaking');
                    audioQueue.push({ data: msg.data, is_final: msg.is_final });
                    if (!isPlayingAudio) playNextAudio();
                    break;
                case 'audio_stream_end':
                    log('Stream end');
                    break;
            }
        }
        
        // AUDIO PLAYBACK QUEUE
        async function playNextAudio() {
            if (audioQueue.length === 0) {
                isPlayingAudio = false;
                if (currentMode === 'voice') {
                    setStatus('LISTENING...', 'listening');
                } else {
                    setStatus('ONLINE - HOLD MODE', '');
                }
                return;
            }
            
            isPlayingAudio = true;
            const chunk = audioQueue.shift();
            
            try {
                const mp3Data = atob(chunk.data);
                const bytes = new Uint8Array(mp3Data.length);
                for (let i = 0; i < mp3Data.length; i++) bytes[i] = mp3Data.charCodeAt(i);
                const blob = new Blob([bytes], { type: 'audio/mpeg' });
                const url = URL.createObjectURL(blob);
                
                const audio = new Audio();
                audio.preload = 'auto';
                audio.src = url;
                audio.volume = 1.0;
                
                await new Promise((resolve, reject) => {
                    audio.addEventListener('canplaythrough', () => audio.play().then(resolve).catch(reject), { once: true });
                    audio.addEventListener('error', reject);
                    audio.load();
                });
                
                await new Promise(resolve => { 
                    audio.onended = () => { URL.revokeObjectURL(url); resolve(); }; 
                });
                
                await new Promise(resolve => setTimeout(resolve, 400)); // ‚Üê Pause pi√π lunghe come JARVIS
            } catch (e) {
                log(`Playback error: ${e}`);
            }
            
            playNextAudio();
        }
        
        // ORB EVENTS (Hold mode)
        orbContainer.addEventListener('mousedown', startRecording);
        orbContainer.addEventListener('mouseup', stopRecording);
        orbContainer.addEventListener('mouseleave', stopRecording);
        orbContainer.addEventListener('touchstart', (e) => { e.preventDefault(); startRecording(); });
        orbContainer.addEventListener('touchend', (e) => { e.preventDefault(); stopRecording(); });
        
        window.addEventListener('resize', () => {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
        });
        
        // AUTO-START
        setTimeout(() => {
            initWebRTC();
        }, 500);
        
        log('JARVIS Unified System Loaded');
    </script>
</body>
</html>
